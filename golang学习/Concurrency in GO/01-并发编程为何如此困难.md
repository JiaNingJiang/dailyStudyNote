## 一、引起并发错误的常见问题

### 1. 数据竞争

当两个或更多的操作必须以正确的顺序执行时，就会出现竞争状态。

大多数时候，这出现在所谓的数据竞争中，其中**一个并发操作尝试在某些未确定的时间读取变量，而另一个并发操作尝试写入同一个变量**。这里有一个简单的例子：

```go
1 var data int
2 go func() { // 1
3     data++
4 }()
5 if data == 0 {
6     fmt.Printf("the value is %v.\n", data)
7 }
```

在第3行和第5行都试图访问名为data的变量，但是并没有施行任何措施保证执行的顺序。运行此代码有三种可能的结果：

- 没有输出。在这种情况下，第3行是在第5行之前执行的。
- 输出 the value is 0。在这种情况下，第5行和第6行在第3行之前执行。
- 输出 the value is 1。在这种情况下，第5行在第3行之前执行，但第3行在第6行之前执行。

**大多数情况下，数据竞争是由于开发人员按顺序思考问题而引入的**。 他们认为，上一行代码会先于下一行代码执行。 他们假设在if语句中读取数据变量之前，上面的goroutine将被调度并执行。

在编写并发代码时，必须仔细地遍历所有可能出现的场景。保证代码将按其在源代码中列出的顺序运行。

 有时在操作之间等待很长一段时间会很有帮助。  想象一下，在调用goroutine的时间和运行的时间之间要经过一个小时。 该程序的其余部分如何运作？  如果在goroutine成功执行和程序到达if语句之间花了一个小时呢？  以这种方式思考对我们有所帮助，因为对于计算机而言，规模可能不同，但相对时间差异差不多。

事实上一些开发者确实这么干并发现看起来解决了并发上的问题，我们修改上个例子看看：

```go
1 var data int
2 go func() { // 1
3     data++
4 }()
5 time.Sleep(1*time.Second) // 这种做法实在太烂了!
6 if data == 0 {
7     fmt.Printf("the value is %v.\n", data)
8 }
```

我们解决了数据竞争问题吗吗？没有。事实上，从这个方案中产生的所有三个结果仍然是可能的。**在调用我们的goroutine和检查数据值之间的让程序休眠的时间越长，程序越接近实现正确性——但这只是在概率上渐近地接近逻辑正确而已。**

除此之外，这样做已经在算法中引入了低效率。 程序现在必须休眠一秒钟才能使我们更有可能看不到的数据竞争。如果我们使用正确的方式来编写代码，我们可能无需等待，或者等待时间可能只有1微秒。

这里要说的是，应该总是以逻辑的正确性为目标。 **在代码中引入休眠可以是一种调试并发程序的方便方式，但不是解决方案。**

**数据竞争的产生条件是最隐秘的并发错误类型之一，因为它们可能在代码投入生产后才会展现出来。 它们通常是由代码执行环境发生变化或前所未有的突发事件引起的。 在这些情况下，代码看起来行为正确，但实际上，这些操作按顺序执行的出现不确定性的几率非常高。**

### 2. 原子性

当某种东西被认为是原子性的或者具有原子性的时候，这意味着**在它运行的环境中**，它**是不可分割的或不可中断的**。

那么这到底意味着什么，为什么在使用并发代码时知道这很重要？

第一件非常重要的事情就是了解“上下文(context)”这个词。**在某个特定的上下文中，有的操作可能是原子的，有的可能不是**。 在你的流程环境中，原子状态的操作在操作系统环境中可能不是原子操作； 在操作系统环境中是原子的操作在你的机器环境中可能不是原子的;  并且在机器上下文中是原子的操作在应用程序上下文中可能不是原子的。 换句话说，**操作的原子性可以根据当前定义的范围而改变**。  清醒的认识到这个事实对你程序的利弊是非常重要的！

**在考虑原子性时，经常需要做的第一件事是定义上下文或作用域，这个操作将被视为原子性的。**这是思考程序的基础。

现在让我们看一下术语“不可分割”和“不可中断”。这些术语意味着在你定义的上下文中，原子的东西将在整个过程中发生，而**不会同时发生任何事情**。 这让人有点糊涂，所以我们来看一个例子：

```go
i++
```

这是一个任何人都可以明白的简单代码，但它很容易证明原子性的概念。 它可能看起来很原子，但是一个简单的分析揭示了几种操作：

- 检索i的值。
- 增加i的价值。
- 存储i的值。

尽管这些操作中的每一个都是原子的，但三者的组合可能不是，取决于你的上下文。  这揭示了原子操作的一个有趣特性：将它们结合并不一定会产生更大的原子操作。 创建操作原子取决于你希望它在哪个上下文中处于原子状态。  **如果你的上下文是一个没有并发进程的程序，那么这个代码在该上下文中是原子的**。 **如果你的上下文是一个不会将 i  暴露给其他goroutine的goroutine，那么这个代码是原子的。**

为什么我们如此在意原子性？原子性非常重要，因为**如果说某些东西是原子的，那么就隐式地意味着在并发环境中是安全的。**这使我们能够编写逻辑上正确的程序，并且——我们稍后将看到——甚至可以用作优化并发程序的一种方式。

大多数语句不是原子的，更不用说函数，方法和程序了。如果原子性是组成逻辑上正确的程序关键，并且大多数语句不是原子的，那么我们如何调和这两个问题？稍后我们会深入探讨，但总之，我们**可以通过采用各种技术来强制原子性**。至于如何决定你的代码的哪些部分需要是原子的，以及需要划分到什么样的粒度，我们在下一节继续讨论。

### 3. 内存访问同步

假设我们有一个数据竞争：**两个并发进程试图访问同一个内存区域，并且它们访问内存的方式不是原子的**。 我们对之前的例子进行一些修改：

```go
var data int
go func() { data++}()
if data == 0 {
    fmt.Println("the value is 0.")
} else {
   fmt.Printf("the value is %v.\n", data)
}
```

我们在这里添加了一个else子句，以便不管数据的值如何，总会得到一些输出。 请记住，正如它所写的那样，**存在数据竞争，并且程序的输出将完全不确定。**

**程序中有一些操作需要独占访问共享资源。**在这个例子中，我们找到三处：

- goroutine正在增加数据变量。
- if语句，它检查数据的值是否为0。
- fmt.Printf语句，用于检索输出数据的值。

有很多方法可以保护这些访问，Go有很好的方式来处理这个问题，**解决这个问题的方法之一是让这些操作同步访问内存。** 让我们看看该怎样做到这一点。

下面的代码不是Go的惯用法（我不建议你像这样解决数据竞争问题），但它很简单地演示了内存访问同步。

```go
var memoryAccess sync.Mutex //1
var value int
go func() {
    memoryAccess.Lock() //2
    value++
    memoryAccess.Unlock() //3
}()

memoryAccess.Lock() //4
if value == 0 {
    fmt.Printf("the value is %v.\n", value)
} else {
    fmt.Printf("the value is %v.\n", value)
}
memoryAccess.Unlock() //5
```

1. 这里我们添加一个变量，它允许我们的代码同步对数据变量内存的访问。
2. 在这里我们声明，除非解锁，否则我们的goroutine应该独占访问此内存。
3. 在这里，我们声明这个对该内存的访问已经完成了。
4. 在这里，我们再次声明接下来的条件语句应该独占访问数据变量的内存。
5. 在这里，我们声明对内存的访问已经完成。

在这个例子中，我们为开发者制定了一个约定。**任何时候开发人员都想访问data变量的内存，必须首先调用Lock，当完成访问操作时，必须调用Unlock。**这两个语句之间的代码可以假定它拥有对数据的独占访问权; 我们已经成功地同步了对内存的访问。注意，如果开发者不遵循这个约定，我们就没有保证独占访问的权利！

你可能已经注意到，**虽然我们已经解决了数据竞争，但我们并没有真正解决竞争条件**！**这个程序的操作顺序仍然不确定**。  我们刚刚只是缩小了非确定性的范围。在这个例子中，仍然不确定goroutine是否会先执行，或者我们的if和else块是否都会执行。  稍后，我们将探索正确解决这类问题的工具。

### 4. 死锁，活锁和锁的饥饿问题

#### 4.1 死锁

**死锁是所有并发进程都在彼此等待的状态。** 在这种情况下，如果没有外部干预，程序将永远不会恢复。
如果这听起来很严峻，那是因为它确实很严峻！ Go运行时会检测到一些死锁（所有的例程必须被阻塞或“休眠”），但这对于帮助你防止死锁产生没有多大帮助。

为了帮助你更直观的认识死锁，我们先来看一个例子。

```go
type value struct {
    mu    sync.Mutex
    value int
}

var wg sync.WaitGroup
printSum := func(v1, v2 *value) {
    defer wg.Done()
    v1.mu.Lock()         //1
    defer v1.mu.Unlock() //2

    time.Sleep(2 * time.Second) //3
    v2.mu.Lock()
    defer v2.mu.Unlock()

    fmt.Printf("sum=%v\n", v1.value+v2.value)
}

var a, b value
wg.Add(2)
go printSum(&a, &b)
go printSum(&b, &a)
wg.Wait()
```

1. 这里我们试图访问带锁的部分
2. 这里我们试图调用defer关键字释放锁
3. 这里我们添加休眠时间 以造成死锁

如果你试着运行这段程序，应该会看到这样的输出：

```go
fatal error: all goroutines are asleep - deadlock!
```

实质上，我们创建了两个不能一起运转的齿轮：我们的第一个打印总和调用a锁定，然后尝试锁定b，但与此同时，我们打印总和的第二个调用锁定了b并尝试锁定a。 **两个goroutine都无限地等待着彼此。**

事实证明，出现僵局时必定存在一些条件，1971年，埃德加科夫曼在一篇论文中列举了这些条件。这些条件现在称为**科夫曼条件**，是帮助检测，防止和纠正死锁的技术基础。

科夫曼条件如下：

**相互排斥**
并发进程在任何时候都拥有资源的独占权。

**等待条件**
并发进程必须同时持有资源并等待额外的资源。

**没有抢占**
并发进程持有的资源只能由该进程释放，因此它满足了这种情况。

**循环等待**
并发进程（P1）等待并发进程（P2），同时P2也在等待P1，因此也符合”循环等待”这一条件。

<img src="https://www.topgoer.cn/uploads/concurrency/images/m_88cc955411fe6188b71dad6f4aa3a356_r.png" alt="null" style="zoom:50%;" />

让我们来看看我们的设计程序，并确定它是否符合所有四个条件：

1. printSum函数确实需要a和b的独占权，所以它满足了这个条件。
2. 因为printSum保持a或b并等待另一个，所以它满足这个条件。
3. 我们没有任何办法让我们的goroutine被抢占。
4. 我们第一次调用printSum正在等待我们的第二次调用，反之亦然。

很好，我们亲手实现了死锁。

科夫曼条件同样有助于我们规避死锁。如果我们确保至少有一个条件不成立，就可以防止发生死锁。不幸的是，实际上这些条件很难推理，因此难以预防。网上大量充斥着被死锁困扰的开发人员的求助，一旦有人指出它就很明显，但通常需要另一双眼睛。