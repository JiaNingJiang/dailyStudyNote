# 一、区块链平台

## 1.1 logrus

1. 自定义的日志输出格式，包括日志等级，日志所在行号、所在文件，生成日志的函数（logrus.Log.Sprintf()所在的函数），生成日志的时间等都可以自行添加并调整顺序。
2. 可以选择日志的输出方向，可以同时输出到多个文件（文件包括标准输出设备）
3. 可以编写自定义的 Write 方法，调整日志输出的方式，比如说按分钟切割日志（每过一分钟将创建一个新的日志文件，将新产生的日志输入到其中），或者是按照日志文件大小进行切割
4. 可以编写若干 Hook ，Hook 必须实现两个接口：
   1. func (xxx *XXX) Fire(entry *logrus.Entry) error{}
   2. func (xxx *XXX) Levels() []logrus.Level {}

​	后者是 Hook 针对的日志等级范围，前者是对该范围内的日志做的自定义处理。比如我们可以将特定等级范围的日志单独输出到一个文件中；或者将感兴趣的具有特定前缀的日志消息单独输出到一个文件中。



## 1.2 下层共识

### 1.2.1 模块运行过程

1. 以 P2P 形式连接的节点网络，通过节点分区算法将其分解为一个个相互独立的子网络。

2. 在每个子网内部，将节点划分为 Leader 节点和 Follower 节点两大类。

3. 每个节点都有一个交易池，负责存储子网内部产生的交易。每当节点从客户节点收集到交易时，会将其存储在本地的交易池中，并且在子网内部进行广播。

4. 子网内的 Leader 节点周期性的通知子网内全部节点启动一轮共识（发送 pre-prepare Msg，简称PPM），该PPM包含了包含三个重要信息：
   1. 当前共识轮次（round ID），该共识轮次的存在使得子网内支持并发的 PBFT 共识，节点的共识处理器（round Handler）只会接收并处理符合自身 round ID 的共识消息。
   2. 待打包交易顺序（TxOrder []common.Hash），下一区块内包含的交易以及其顺序需要在本分区内完成共识。
5. 子网内的 Follower 节点收到 PPM 消息后，首先需要在本地创建一个新的 round Handler，单独负责此轮的 PBFT 共识。之后，Follower 节点便向子网内其他节点广播一条 Prepare Msg（简称 PM ）。PM 中包含了以下几条重要内容：
   1. round ID
   2. validOrder：当前 Follower 所认为包含在 PPM 中的交易集合中交易的合法情况（若本地有此交易标记为1；若没有标记为0）
6. 在后续的 Prepare 阶段，节点针对收到的 PM 中的 validOrder，确认出多数节点（PBFT 中此数量为 2*f+1 ）认可的交易以及交易顺序。节点将基于此构建下一阶段的消息（Commit Msg，简称CM），将其发送给 Leader 。CM中包含了以下内容：
   1. round ID
   2. Next Block（包含了经过共识的有序交易集合）
   3. 当前节点针对此 CM 消息的数字签名
7. Leader 节点收到各个 Follower 的 CM，将包含相同区块的 CM 聚集在一起，如果消息的数量大于等于 2*f + 1，那么组装出本分区最后要提交的区块，其中包含支持该区块的所有节点的数字签名。
8. 一轮共识结束，销毁本轮使用到的 round Handler。

### 1.2.2 问题与解决

问题：原始的 PBFT 算法，每次针对一个事务（交易）进行一次共识，整体的共识效率很低（TPS 很低）

该共识算法主要从两方面进行了改进：

1. 一次针对若干笔交易进行共识，Leader 节点并不是收到一笔交易就立即展开一轮 PBFT 共识，而是会将从客户节点获取的交易存储在本地的交易池中，每隔一段时间从中取出部分交易，一起进行共识。为了防止区块包含零交易，如果当前交易数为 0 ，则 Leader 不会发起共识
2. 分区内部并行运行多轮 PBFT 共识，Leader 节点每次开启一轮 PBFT 共识，就会创建一个 round Handler（通过 roundID 唯一标识），单独负责本轮次的 PBFT 共识，不同轮次的 PBFT 共识之间相互独立。各轮次并行的将分区内获得的交易打包成区块，缓存在 Leader 的区块缓存中，每当收到上层排序节点的请求后，从缓存中取出一个区块进行上层共识。

## 1.3 下层共识的视图切换

### 1.3.1 模块运行过程

1. 启动时机：当分区内的 Follower 节点长期无法收到来自 Leader 的 PPM，也就是说分区内已经很长时间没有进行过 PBFT 共识了，此时 Follower 节点们会认为 Leader 节点已经失效，需要重新选举一个 Leader 节点。

2. 每个 follower 节点向分区内的其他 follower 节点发送一条 view-change Msg（简称 VCM），VCM 内包含了下述信息：

   1. 当前视图 ID , View-ID，这是一个依次递增的变量。

   2. 下一视图ID，在当前视图ID的基础上+1
   
3. 当 follower 节点收到至少 2*f+1 条有效的VCM时，则会认为确实需要更换 Leader 节点，那么它会暂停当前正在运行的 round Handler，同时根据下一视图 ID 计算出新 Leader 是谁，然后在分区内广播 New-View Msg（简称 NVM）。NVM 包括：下一视图ID 和 计算出来的新 Leader 节点，当前正在运行的 roundHandler 的 roundID.
4. 正常情况下，分区内 follower 们计算出来的新 Leader 节点都是同一个，那么当该节点收集到至少 2*f+1 条 NVM 后，就确定自身被选为下一个 Leader 节点，那么它就会在分区内部广播 Leader-Change Msg（简称LCM），通知包括自身在内的其他 Follower 节点更改分区内拓扑结构，将旧 Leader 调整为 Follower，用新的 Leader 去代替。
5. 完成 Leader 更换后，针对于上一轮尚未完成的 round Handler，则继续运行完成共识。
6. 由于本系统是一个双层分区网络，新的分区 Leader 还需要通告其他分区 Leader ，告知他们本分区的 Leader 节点已更新。

### 1.3.2 问题与解决

**问题一**

系统是一个双层共识网络，各个下层分区的 Leader 节点和排序节点共同组成了整个上层分区网络，当某一个分区的 Leader 节点被分区内的其他 Follower 节点替换掉之后，上层分区的其他节点需要获知此消息，并调整上层分区网络的拓扑信息。

**解决一**

故障分区的新 Leader 节点必须从**排序节点**处获取上层分区的网络拓扑结构（上层分区所有节点的地址信息），新 Leader 节点需要利用**网络分区模块提供的接口**向上层分区内的节点发送加入请求，加入请求需要携带故障分区内其它 Follower 节点的数字签名（保障安全性，节点不能随意加入上层分区网络）

**问题二**

故障的 Leader 节点恢复正常后可能会重新加入到所在分区网络。但是该节点无法意识到自身已经不再是分区内的 Leader 节点，因此后续无法正常参与分区内的 PBFT 共识

**解决二**

Leader 节点的 View-Change 模块也需要运行，只不过其内容与 Follower 节点不同，仅仅是向分区内的 Follower 节点发送确认请求，确认的内容则是当前分区内 Leader 节点的哈希值，如果发现有超过 2*f+1 的 Follower 节点都认为 Leader 节点已经更换，则当前节点会调用网络分区模块的接口重构本地的网络拓扑，将自身调整为 Follower ，并更新新的 Leader。

**问题三**

基础的视图切换面对下面这种情况时可能会浪费一轮时间：当前 Leader 失效，同时应当选为下一 Leader 的节点也失效了。那么当前运行视图切换的 follower 们可能会进行发送多次 VCM 和 NVM ，因为本该回复他们的新 Leader 节点失效了。这就浪费了很多无用的时间和资源。

**解决三**

引入了心跳机制：分区内的各个节点之间互相发送心跳包，这样节点就可以事先获知下一轮要选举出来的 Leader 是否还存活，如果已经失活，则直接跳过即可。

## 1.4 上层共识

### 1.4.1 模块运行过程

1. 组成：上层分区由各下层分区 Leader 节点，以及提供区块排序服务的特殊 Booter 节点共同组成。
2. Leader 节点的上层模块会缓存来自下层分区提交的区块，每当获取到一个新的下层区块后，当前 Leader 就会在上层分区内对该区块进行广播，这其中就包括了 Booter 节点。
3. Booter 节点从 Leader 节点们广播的区块中，选取一个区块作为整个区块链账本的下一区块，将该区块的 BlockID 放入 CODE_NEXT Msg（简称CNM）中进行广播
4. 其他 Leader 节点在收到该 CNM 后，则会对该区块进行验证（检验是否存在？数字签名数量是否足够？等等），验证通过后对区块内交易进行执行（基于智能合约），然后生成交易执行回执，将所有交易回执求哈希获取区块回执， 最后生成一条 CODE_SIGN Msg（简称 CSM），其中包括：1.区块的验证结果  2. 区块的ID  3.区块回执  4.针对回执的数字签名。将 BOM 发送给 Booter 节点。
5. Booter 节点收到该 CSM ，就可以获取其他 Leader 节点的确认情况，如果超过半数的 Leader 认为此区块合法且执行回执相同，则 Booter 节点会针对此区块再次生成 CODE_CMIT Msg（简称CCM），将其广播给所有 Leader；如果不是，则重新选择一个区块重新发送 CNM，而且会通告所有 Leader 节点对执行的交易进行回滚。
6. Leader 节点们在收到 CCM 后，如果是失败的结果，则会对交易进行回滚，重新等待接收新的 CNM。如果是成功的结果，则会将该区块进行最终的落盘，结束后，Leader 向 Booter 节点发送 CODE_DONE Msg（简称 CDM）。
7. 当 Booter 节点收到多数节点的 CDM 后，选取下一个要落盘的区块，再次进行下一轮区块排序。

**注：为了保证能够实现交易的回滚，在世界状态 Level DB 中每一个 key 需要保存上一个版本的 value。**

### 1.4.2 问题和解决

问题：如果上层分区的某一个 Leader 节点因为某些原因长时间未参与上层的区块排序共识（比如因为所在的下层分区发生了 View-Change），这就会导致该 Leader 的最新区块哈希 currentVersion 与上层分区的其他节点不同步，导致该 Leader 所在的整个分区都无法产生正常的区块而且也无法正常参与排序共识

解决：Leader 在每次重新启动（宕机重启动或者新 Leader 上线）上层排序共识模块时，都会向 Booter 节点发送自身的最新区块哈希 currentVersion，Booter 节点判断此 Leader 的 currentVersion 是否是最新的，如果不是则通知该 Leader 节点开启区块同步模式，在完成同步之前，该分区的 Leader 节点不会参与上层分区的区块排序共识，同时也不会要求自身分区的 Follower 节点开启 PBFT 共识。

## 1.5 上层共识的鲁棒性保证

目的只是为了保证排序节点的单点故障问题。提供了多个冗余的排序节点，当现任的排序节点无法正常工作时，对排序节点进行更换，继续为上层分区的其他节点提供排序服务。

采用的是 Raft 算法。

1. Booter 节点集群，每一时间只有一个 Booter 节点在与其他 Leader 通信，其他的 Booter 则需要从主 Booter 上同步信息，同步的内容如下：
   1. 上层分区所有 Leader 节点的地址信息
   2. 当前区块链的最新区块哈希 Current Block Hash
   3. 从各个 Leader 处获得的缓存区块的 BlockID
   4. 当前排序服务所处的共识状态，以及所选择的下一个区块
2. Booter 集群内的副本节点需要即使探测主节点的工作状态，一旦发现以下两种情况发生，则进行主节点的更换：
   1. 在 life_cycle（每个节点的该计时器时长不一样，目的就是为了防止有多个节点搜集到了相同票数的 vote，导致需要重新选举 Leader） 结束前，没有收到主节点的心跳包，则认为需要更换主节点
   2. 发现 Current Block Hash 长时间未发生变化，也就说整个区块链系统长时间没有落盘区块。（该情况在进行主节点切换前，需要再**运行一个随机时长的计时器**，随机的原因是确保每个节点启动主节点切换的时机不一样）
3. 完成 Raft 算法中的主节点切换工作：
   1. 最先认为主节点失效的节点，向分区内其它节点发送 Change_Request Msg（CRM），包括新视图ID；同时将自己的 vote--（每个节点在每一个视图下 vote 值为1）
   2. 其它节点对最先收到的 CRM 进行回复，如果发现 New View ID 比自己的 View ID要大，则将自身的 vote 投给发送节点（如果自己的vote还存在）
   3. 如果一个节点率先收集到一半以上的 vote，则会通知其他节点自己将成为新的主节点，广播 New_Leader_Msg(简称 NLM)
   4. 其他副本节点收到该 NLM，则更新本地的网络拓扑，将其更改为新的 Leader。
   5. **注：类似于 PBFT 的视图切换，Booter 分区内的主节点也要在重新恢复连接之后，重新向分区内节点确认自身是否仍是主节点，如果不是则需要作为副本节点运行（从新的主节点处同步状态）。**
4. 新的主节点需要作为新的 Booter 采取以下措施：
   1. 根据之前的信息与 Leader 节点们进行连接，进入到同一个网络分区
   2. 通知 Leader 节点们 Booter 节点已经进行了切换
   3. 根据之前同步到的状态，继续提供区块排序服务。

## 1.6 网络分区模块的动态调整

在 P2P 网络之上构建彼此之间相互独立的分区网络，分区内的节点之间是 P2P 全连接的，任意一个区块链节点只能向同一分区内的其他节点发送交易消息和共识消息。分区内的广播消息不会扩散到其他分区。

第一版实现的网络分区模块是一个静态的网络节点，无法实现分区内节点的退出和加入操作（只能在初始化阶段构建分区网络）。

第二版在第一版的基础之上，实现了对网络的动态调整功能：

### 1.6.1 节点的重连接

分区内的节点可能因为某些原因断开了与分区内其它节点的 TCP 连接，当再次恢复时因为没有保留其它节点的地址信息而无法重新连接。

最简单的思路是：让节点在第一次连接时保存同一分区内的其他节点的 TCP 地址信息，节点在断连之后能够重新连接。

问题：无法保证节点在断连到重连期间，分区内的拓扑结构没有任何变化，可能又有许多别的新节点加入，也可能之前的节点退出了。而且修改 P2P 模块代码相对复杂。

解决：不在 P2P 层解决，而是在网络分区层进行解决。网络中的 Booter 节点不仅负责进行区块排序服务，同时还担任 P2P 网络构建过程中“引导节点”的工作，其他节点在加入到区块链网络之前都必须先与 Booter 节点建立连接（Booter 节点的地址是固定的），通过 Booter 间接的与其他节点进行连接，因此可以**让 Booter 节点维护区块链网络的最新拓扑结构**。

**Booter 节点不仅需要保存所在的上层分区网络的最新拓扑结构，还需要保存其他所有下层分区的最新网络拓扑结构**，其他节点在动态加入、退出某分区时，都必须通知 Booter 节点，让 **Booter 节点对网络状态进行实时更新**。

因此节点在断连又重新连接之后，就可以直接向 Booter 节点“索要”所在分区的最新网络拓扑结构，然后向这些节点发送重连请求，重新加入所在分区。

### 1.6.2 节点加入某分区

节点向 Booter 节点发送请求，请求目标加入分区的网络拓扑结构，然后向分区内节点发送加入请求，完成加入

## 1.6.3 节点加入某分区

节点直接向所在分区的其他节点发送退出请求，之后再向 Booter 节点发送退出请求

## 1.6.4 节点身份变更

实现节点身份的变更，从分区的 `Leader` 变成 `Follower` ，或者从 `Follower` 变成 `Leader`。当状态发生变更之后，通知 Booter 节点。



## 1.7 区块同步服务

1. 作用：有两种情况会使用到区块同步模块
   1. 情况一：正常情况下，上层分区的 Leader 节点们会执行并落盘区块，但是各分区的 Follower 节点不会进行此操作，因此 Follower 节点必须从所在分区的 Leader 节点处获得最近落盘的区块
   2. 情况二：节点因某些情况从网络中断连了一段时间，重新加入网络时，需要从所在分区的其他节点处同步最新的区块，如果是 Leader 节点，在同步到最新的 currentVersion 之前，不能参与区块排序共识。

2. 同步的对象：假设同步者A的区块高度是X，它首先会选择一个同步对象，选择的基准是区块高度差的大小，也就是选择一个具有**最高区块高度**的**合法**节点（如果发现同步过来的区块有非法的，则该节点会被记录到非法名单）进行同步。
3. 同步的过程：
   1. 假设同步者A的区块高度是X，被同步者B的区块高度是Y，要同步的区块范围是 X~Y，同步不会一蹴而就，而是分批进行的。节点 A 一次向节点 B 请求 MaxFetch（默认是20个） 个区块。
   2. 节点 B 收到 节点 A 的同步请求后，首先会判断两个节点主链上的**最近公共祖先区块Z**，然后从 Z 开始向 A 返回 MaxFetch 个区块，如果不到 MaxFetch 个就返回已有所有的。
   3. 节点 A 收到节点 B 返回的区块集合之后，会针对每一个区块进行验证（验证哈希值和包括的数字签名，合法的数字签名需要包含：所在分区PBFT容限数量的投票，上层分区一半节点数量的投票），如果验证通过则落盘到本地；如果验证失败，则后续所有区块都扔掉，同时标记该节点为非法节点，继续选择其他合法节点进行同步。

## 1.8 区块链存储模块

### 1.8.1 区块链状态数据的存储

状态数据主要包含以下内容：

1. 当前区块高度、最新的区块哈希
2. 智能合约所涉及的状态量：以简单的转账合约为例，存储了每个账户的账户地址以及该账户的余额。

这部分数据一般以 k-v 的形式出现，在区块链执行交易阶段，需要反复进行更改或写入， 对读写速率要求比较高，因此选择使用 k-v 型数据库 levelDB

### 1.8.2 区块链区块数据的存储

区块数据就是指存储各种交易的区块账本本身，这些数据本身只是记录交易执行的结果，而且仅在最终区块落盘的时候需要写入，已经落盘的区块也不再会进行修改。

这部分数据写入的频率不是很高，但是可能需要供用户查询。因此，对于这部分数据采用查询功能更加强大的关系型数据库 MySQL 进行存储。

存储的时候，分为两张表：区块表和交易表。

1. 区块表：以区块高度作为主键进行存储
2. 交易表：以 "区块高度 + 区块内交易下标" 的组合作为主键进行存储

有的时候，用户可能对特定分区产生的区块感兴趣，因此在区块表中，针对（区块来源分区字段）建立了索引

有的时候，用户可能对特定合约产生的交易感兴趣，因此在交易表中，针对（合约名称字段，合约函数名称字段）建立了联合索引

## 1.9 区块链接口模块

第一版基于 Gin 框架实现，主要与区块链前端进行通信

第二版基于 grpc-gateway 实现，同时可以通过 Restful API 和 rpc 完成与区块链后端的通信，前者用于前端与后端的通信，后者用于客户端与后端的通信。

## 1.10 分布式构建脚本

### 1.10.1 配置文件

在 `config.ini` 配置文件中进行网络拓扑结构的设置以及各个节点工作状态的配置。

网络拓扑结构：

- 网络中节点的总数
- 网络中的分区数目
- 各分区内网络节点的数目，包括 Leader 的数量和 Follower 的数量

节点配置信息：

- 节点的基础属性配置信息，包括所在子网，节点身份，网络地址信息（IP:PORT），各类文件（日志文件，状态存储文件）的存储目录等等。
- 节点的运行模式：前台进程方式启动 or 后台进程方式启动
- 合约配置信息：运行的合约以及合约程序的地址
- 其余功能模块的配置信息：日志模块的配置信息、网络接口模块的配置信息、加密模块的配置信息（是否国密算法）、数据归档模块的配置信息等等。

### 1.10.2 各节点文件的生成

根据第三方库 `go-ini` 读取配置文件 `config.ini` 的内容，为分布式区块链网络的各个节点生成相应的节点文件夹（包括可执行文件和相关的配置文件）

### 1.10.3 各节点文件的移动

存储所有节点文件夹的主机被称为主节点，其余的主机被称为副节点。

将主节点上的各个节点文件夹通过 scp 命令拷贝至相应 IP 地址的其他主机上。（使用 scp 命令前需要将当前主机的公钥在其余主机上存储，这样 scp 命令 不会要求输入 用户名和密码 ）

### 1.10.4 区块链的分布式启动与停止

有两种分布式启动方式：

1. 直接使用 ssh 远程调用各节点文件的区块链启动/停止脚本。
2. 使用 docker-compose up/down 完成分布式区块链网络各节点的启动/停止。

## 二、基于区块链平台的分布式动态频谱管理系统

### 2.1 基本架构

区块链前端网页  -- 分布式动态频谱管理系统 -- 区块链平台

​			 |									   |

​			 |--------------   存储AP频谱的分布式数据库

动态频谱管理系统主要分为以下几个部分：

- 区块链平台与前端页面的解码器，负责接收前端的 Web 请求，从区块链平台获取区块/交易数据，对区块和交易进行解码后（区块链中区块中保存的交易是以加密的形式存储的，正常显示还需要解密）返回给前端页面。
- 与分布式数据库管理系统的连接接口：
  - 功能一：负责从 MySQL 数据库读取各 AP 的实时信息，包括 AP 的标识符、AP 的地理地址、AP的覆盖面积、AP功率、AP的信道占用率、AP的空闲信道等等
  - 功能二：当管理系统完成对各 AP 空闲信道的调整以及信道占用率的修改后，在 MySQL 中对相应的 AP 数据行进行修改。
- 与区块链平台的接口，将不同 AP 间空闲信道的转移过程作为交易事件上传到区块链平台进行上链。同时依据消息订阅模块动态的从区块链上获取其他节点上链的不同类型的交易。

### 2.2 分布式动态频谱管理系统的运行

整个 AP 间空闲信道的转移过程会产生以下几种类型的交易：

- `IssueAPChannelInfo`

当从数据库管理系统获取到一条新 AP 的相关信息时，会产生该类型的交易，将其上传至区块链平台进行上链。当前节点在完成此交易的上链之后，其他节点基于消息订阅模块也会获取到该交易，从而解析出相应的 AP 信息。

除此之外，区块链的状态数据库也会记录（AP标识符，APInfo）的键值对，记录下每个 AP 的状态信息。

- `IssueBidingPriceInfo`

每一个节点会存储两种类型的 AP 信息：一种是从与自身连接的数据库管理系统中获取的（称为 SelfAPs），另一种是通过事件订阅从其他节点处获得的（其他节点上传到区块链上的）(称为 OtherAPs)。

如果当前节点检测到自身所管理的 AP 的信道占用率过高（>=0.8），表名当前 AP （buyerAP）急需从其他 AP 处获取空闲信道，此时当前节点就会从 SelfAPs 以及 OtherAPs 中查询获取一个最适合（根据**相关算法**决定）的 AP（sellerAP）以及最合适的空闲信道，作为交易的发起方调用智能合约请求完成 buyerAP 和 sellerAP 间空闲信道的转移，将其以交易的形式上传到区块链。

其他节点根据消息订阅模块从区块链上获取到该交易，可以从中提取出 buyerAP ， sellerAP，请求要转移的空闲信道，buyerAP 的出价。

- `IssueChannelSwitchInfo`

如果当前节点管理的 AP 有很多空闲信道（占用率<=0.2），那么当前节点可能会收到许多其他节点的空闲信道转移请求（即 `IssueBidingPriceInfo` 交易），那么当前节点会根据**相关算法（出价最高的）**对这些"交易请求"进行回应，每个空闲信道只能被转移给一个请求者。

回应的形式就是产生 `IssueChannelSwitchInfo` 交易，其中包括 `buyerAP` 和 `sellerAP` 的标识符以及本次交易被转移的空闲信道。

智能合约将基于此类型的交易，将 `buyerAP` 和 `sellerAP` 在状态数据库中的 APInfo 进行修改（信道的转移和货币的转移），同时生成一条 `UpdateAPChannelInfo` 类型的交易。

- `UpdateAPChannelInfo` 

该类消息作为一次空闲信道转移交换的结果，存储了 `buyerAP` 和 `sellerAP` 的新状态，所有的节点通过事件订阅模块获取到该交易，对涉及到的 `buyerAP` 和 `sellerAP` 的状态在本地进行更新。如果发现 AP 属于 SelfAPs，还会将该更新后的 APInfo 回复给数据库模块。

### 2.3 问题和解决

在第一版频谱管理系统中，各管理节点各自运行一个状态机。状态机在不同的阶段发送不同的事件给区块链节点完成上链，同时通过从区块链节点获取的订阅结果完成状态的切换。

各节点必须以同步的方式完成状态的转移，这要求整个系统具有严格的时序性，一旦某节点因为网络拥塞或者程序执行逻辑较长等状况无法及时与其他节点达成同步，可能导致：**当前节点在其他节点切换到下一状态后才发送当前状态下的事件给区块链节点，导致其他节点虽然通过订阅模块捕获到了该行为，但因为状态不同无法进行处理**。以至于该落后节点在后续一直得不到状态的更新，简单来说，就是整个系统的容错率比较低。

在第二版中，不再使用"状态机"作为程序处理逻辑，而是通过引入"消息池"和"消息回调函数"实现节点之间的异步运行，同一时间只有存在"频谱交易行为"的两个节点才会以同步的方式运行，不必让所有节点都以同步的方式运行。

管理节点从区块链节点获取的所有订阅通知消息都会被放入到节点对应类型的消息池中。如果某管理节点上传了一个"信道购买请求"，此请求不一定会被所有的管理节点所处理，只有当前处于"等待信道购买请求"状态的节点会对其进行处理。这种程序逻辑允许各节点之间异步运行，提高系统容错率的同时也提高了系统的交易处理能力。

总结：第一版系统要求所有节点都以同步的方式运行，所有节点都必须以“同样的上一状态”切换到“同样的下一状态”；第二版系统仅要求存在"频谱交易"的双方节点以同步的方式运行，不参与此次交易的其他节点无需与他们保持同步。
